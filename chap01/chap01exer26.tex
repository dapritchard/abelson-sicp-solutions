\documentclass{article}

\usepackage[margin=3cm]{geometry}
\usepackage[fleqn]{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{mathtools}
\usepackage{listings}
\usepackage[x11names]{xcolor}
\usepackage{titlesec}

% define a global font for listings environments
\lstset{basicstyle=\fontsize{9.5}{10.5}\fontfamily{pcr}\selectfont}

% define a listings environment for Scheme
\lstdefinestyle{scheme}{%
frame=lines,
language=lisp,
basicstyle=\fontsize{9.5}{10.5}\fontfamily{pcr}\selectfont,
keywordstyle=\color{Blue1},
commentstyle=\color{DarkOrchid4},
morekeywords={define, if},
deletekeywords={count, gcd, exp}
}

% new theorem-like environment
\newtheorem{proposition}{Proposition}
\newtheorem{theorem}{Theorem}

\DeclareMathOperator{\GCD}{GCD}
\DeclareMathOperator{\fib}{Fib}

% redefine section headers size
\titleformat{\section}[hang]
{\bfseries}
{}
{0em}
{}
% section and subsection spacing
\titlespacing*{\section}{0pt}{10mm plus 1ex minus .2ex}{4mm plus .2ex}




\begin{document}


% question ---------------------------------------------------------------------

\noindent \textbf{Exercise 1.26:} Louis Reasoner is having great difficulty
doing Exercise 1.24.  His \lstinline{fast-prime?} test seems to run more slowly
than his \lstinline{prime?} test.  Louis calls his friend Eva Lu Ator over to
help.  When they examine Louis's code, they find that he has rewritten the
\lstinline{expmod} procedure to use an explicit multiplication, rather than
calling \lstinline{square} as follows. \vspace{1mm}

\begin{lstlisting}[style=scheme]
(define (expmod base exp m)
  (cond ((= exp 0) 1)
        ((even? exp)
         (remainder (* (expmod base (/ exp 2) m)
                       (expmod base (/ exp 2) m))
                    m))
        (else (remainder (* base (expmod base (- exp 1) m))
                         m))))
\end{lstlisting}
``I don't see what difference that could make,'' says Louis.  ``I do,'' says
Eva.  ``By writing the procedure like that, you have transformed the
$\Theta(\log n)$ process into a $\Theta(n)$ process.''  Explain.

\vspace{3mm}
\hrule




\section{Introduction}

A cursory examination shows that when the input to \lstinline{exp} is even, then
this modification causes there to be two recursive calls to \lstinline{expmod}
as opposed to one call in the original version.  Thus our task is to asses the
complexity of this new procedure call graph.

For this analysis we will need to make use of the fact that the complexity of
each call to \lstinline{expmod} is a constant-time operation for fixed values of
\lstinline{base} and \lstinline{m}.  In general, the complexity for any call to
\lstinline{expmod} is a function of the magnitude of the value returned from the
recursive call(s) to \lstinline{exmod} (recall a related discussion of this
issue in Exercise 1.25).  However, since this value is guaranteed to be less
than \lstinline{m} due to the call to \lstinline{remainder}, we can establish an
upper bound on the complexity of any call to \lstinline{expmod} in call graph.

Thus, based on the above discussion, we can base our cost analysis on the total
number of calls to \lstinline{expmod} as a function of the value of
\lstinline{exp}.  Let $f$ be a function that maps the value of \lstinline{exp}
to the number of total calls \lstinline{expmod} required to calculate the
result.  So for example, $f(2)$ requires an initial call to \lstinline{expmod}
with a value of 2 as input for \lstinline{exp}, which calls two instances of
\lstinline{expmod} each with a value of 1 as input for \lstinline{exp}, each of
which in turn calls an instance of \lstinline{expmod} with a value of 0 as input
for \lstinline{exp}, for a total of 5 calls to \lstinline{expmod}.  Thus, we can
express this same call graph as
$f(2) = 1 + 2 f(1) = 1 + 2(1 + f(0)) = 1 + 2(1 + 1) = 5$.




\section{Preliminary results}

In this section, we will establish some results that will help to calculate the
runtime complexity.  The intuition for Proposition \ref{thm:f-powers-of-two} is
that when the initial input for \lstinline{exp} to \lstinline{expmod} is a power
of 2, let's say $2^k$, then it takes $2^{k + 1} - 1$ calls to \lstinline{expmod}
to reduce the call graph to only calls with inputs of 1 for \lstinline{exp}, and
then another $2^k$ calls to \lstinline{expmod} with 0 as an input for
\lstinline{exp}, giving us a total of $2^{k + 1} - 1 + 2^k = 3 \cdot 2^k - 1$
calls.

\begin{proposition}
  \label{thm:f-powers-of-two}
  Let $k$ be a nonnegative integer.  Then $f(2^k) = 3 \cdot 2^k - 1$.
\end{proposition}

\begin{proof}
  We proceed with proof-by-induction.  The base case is true since
  $f(2^0) = f(1) = 2 = 3 \cdot 2^0 - 1$.

  Next, for the induction step, assume that the claim is true for some value
  $k$.  Then
  \begin{equation*}
    f(2^{k + 1})
    = 1 + 2f(2^{k + 1} /\, 2)
    = 1 + 2f(2^k)
    = 1 + 2 \left[3 \cdot 2^k - 1 \right]
    = 3 \cdot 2^{k + 1} - 1,
  \end{equation*}
  which completes the proof.
\end{proof}

Next we will establish an upper bound for the number of calls required to
\lstinline{expmod}.  The intuition for this upper bound is that when the input
for \lstinline{exp} is odd, then we have to make an ``extra'' call to
\lstinline{expmod}, loosely speaking, before dividing the value of
\lstinline{exp} by 2 in the recursive call.  This can essentially double the
total number of calls to \lstinline{expmod} in the worst case, so the upper
bound is about two times the number of calls for when $n$ is a power of 2.

\begin{proposition}
  \label{thm:f-non-powers-of-two}
  Let $k$ be a nonnegative integer.  Then for any nonnegative integer $n$ with
  $n < 2^k$, it follows that $f(n) < f(2^{k + 1}) - 1$.
\end{proposition}

\begin{proof}
  We proceed with proof-by-induction.  For the base case, let $k = 0$.  Then
  $2^0 = 1$, so we have to establish the result for $n = 0$.  This is true since
  $f(0) = 1 < 4 = (3 \cdot 2^{0 + 1} - 1) - 1$.

  Next, assume that the claim holds for some value $k$, and let $n < 2^{k + 1}$.
  We consider two cases.  First, suppose that $n$ is even.  Then since
  $n/2 < 2^k$, it follows from the induction hypothesis that
  \begin{equation*}
    f(n)
    = 1 + 2 f(n/2)
    < 1 + 2 \left[ f(2^{k + 1}) - 1 \right]
    = 1 + 2\left[ (3 \cdot 2^{k + 1} - 1) - 1 \right]
    = f(2^{k + 2}) - 2.
  \end{equation*}
  Now, suppose that $n$ is odd.  Then, using the previous result for even values
  of $n$, we have
  \begin{equation*}
    f(n)
    = 1 + f(n - 1)
    < 1 + \left[ f(2^{k + 2}) - 2 \right]
    = f(2^{k + 2}) - 1
    % = 1 + 2 f\big( (n - 1) / 2 \big)
    % \leq 1 + 2 \left[ f(2^{k + 1}) - 1 \right]
    % = 1 + 2\left[ 3 \cdot 2^k - 1 \right]
    % = f(2^{k + 1}),
  \end{equation*}
  which completes the proof.
\end{proof}

Now we will establish a lower bound for the number of calls required to
\lstinline{expmod}.  The expectation is that when the input for \lstinline{exp}
is a power of 2, then it will require fewer total calls to \lstinline{expmod}
than any larger input, which is borne out in the proposition below.

\begin{proposition}
  \label{thm:f-lower-bound}
  Let $k$ be a nonnegative integer, then for $n \in \mathbb{N}$ such that
  $2^k \leq n < 2^{k + 1}$, it follows that $f(2^k) \leq f(n)$.
\end{proposition}

\begin{proof}
  We proceed with proof-by-induction.  For the base case, let $k = 0$, then the
  only value of $n$ that satisfies $2^0 \leq n < 2^1$ is $n = 1$.  But then the
  claim is vacuously true since $f(2^0) = f(1)$.

  Next, assume that the claim holds for some value $k$, and fix $n$ such that
  $2^{k + 1} \leq n < 2^{k + 2}$.  We consider two cases.  First, suppose that $n$ is
  even.  Then since $2^k \leq n / 2$, it follows from the induction
  hypothesis that
  \begin{equation*}
    f(n) = 1 + 2 f(n / 2) \geq 1 + 2f(2^k) = f(2^{k + 1}).
  \end{equation*}
  Now, suppose that $n$ is odd.  Then, using the previous result for even values
  of $n$, we have
  \begin{equation*}
    f(n) = 1 + f(n - 1) \geq 1 + f(2^{k + 1}) \geq f(2^{k + 1}).
  \end{equation*}
  Since the choice of $n$ is arbitrary among $2^{k + 1} \leq n < 2^{k + 2}$,
  this completes the proof.
\end{proof}




\section{Final result}

Now that we have the necessary propositions in place, we will prove the main
claim that the \lstinline{expmod} procedure runs in $\Theta(n)$ time.  From
Propositions \ref{thm:f-powers-of-two} and \ref{thm:f-lower-bound}, we have
\begin{equation*}
  f(n)
  \geq f \big(2^{\lfloor \log_2 n \rfloor} \big)
  = 3 \cdot 2^{\lfloor \log_2 n \rfloor} - 1
  \geq 3 \cdot 2^{(\log_2 n ) - 1} - 1
  = \frac{3n}{2} - 1.
\end{equation*}
% \begin{equation*}
%   % f(n)
%   % \geq f \big(2^{\lfloor \log_2 n \rfloor} \big)

%   % \geq f \big(2^{(\log_2 n) - 1} \big)
%   % \geq \frac{3n}{2} - 1.
% \end{equation*}
Next, from Propositions \ref{thm:f-powers-of-two} and
\ref{thm:f-non-powers-of-two}, we have
\begin{equation*}
  f(n)
  \leq f \big(2^{\lceil \log_2 n \rceil + 1} \big)
  = 3 \cdot 2^{\lceil \log_2 n \rceil + 1} - 1
  = 3 \cdot 2^{(\log_2 n ) + 2} - 1
  = 12n - 1
\end{equation*}
These last two statements in combination give us the desired result that the
\lstinline{expmod} procedure runs in $\Theta(n)$ time.








\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
